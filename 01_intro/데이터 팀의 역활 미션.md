# 🏗️ 데이터 인프라와 데이터 엔지니어링 개요

## 📌 데이터 팀의 역할과 미션

### 🎯 데이터 조직의 미션
- **신뢰**할 수 있는 데이터를 바탕으로 **부가 가치**를 생성
- "데이터는 새로운 석유"
- 데이터팀은 **서포트 조직**에 가까움
- 잘못된 데이터 사용은 오히려 **위협**
  - 개인정보의 적절한 사용
  - 데이터 품질 관리: **Garbage In, Garbage Out**
  - 이를 위한 **데이터 거버넌스** 필요

---

## 🚀 데이터 조직이 만들어내는 부가가치

### 1️⃣ 데이터 기반 의사결정
- **Decision Science 팀 (데이터 분석가)**
- 고품질 데이터를 기반으로 의사 결정자에게 인사이트 제공
- **Data-Informed Decisions** vs **Data-Driven Decisions**
- 데이터 기반 지표 정의, 리포트 생성, 대시보드 설계

### 2️⃣ 데이터 기반 제품 개선
- **Product Science 팀 (데이터 과학자)**
- 머신러닝을 통해 사용자 경험 개선 & 프로세스 최적화
  - 개인화 추천/검색
  - 공장 공정 오류 예측, 고장 예측 등

---

## 🏗️ 데이터 인프라란?

### 데이터 기반 활동의 기반: **데이터 인프라**
- 정제된 데이터 수집·저장·전달을 위한 체계
- **데이터 엔지니어**의 역할이 중요

### 데이터 인프라 구성 요소
- **데이터 웨어하우스 (DWH)**  
  - 정제된 구조화 데이터를 저장하는 중앙 DB
  - SQL 기반, 관계형 DB  
- **데이터 레이크 (Data Lake)**  
  - 정형 + 비정형 데이터를 원본 형태로 저장
  - 스토리지 중심, Raw Data 보존

- **데이터 파이프라인 (ETL/ELT)**
  - 데이터를 수집, 정제, 저장하는 일련의 처리 과정  
  - 대표 도구: `Airflow`, `Spark`, `Kafka` 등  
  - 실시간 처리 시에는 `Kafka`, `Kinesis` 활용

### 인프라 고도화
- 데이터 크기 증가 시:
  - **Spark / Hadoop** 기반 분산 처리 필요
  - **데이터 레이크**로 Raw Data 저장
- 머신러닝 확장 시:
  - **MLOps 파이프라인** 구축
- LLM 및 GenAI 활용 시:
  - **LLMOps / AI Engineering** 등장

---

## 🧱 데이터 웨어하우스 vs 데이터 레이크

| 항목 | 데이터 웨어하우스 | 데이터 레이크 |
|------|------------------|----------------|
| 데이터 형태 | 구조화 | 구조화 + 비구조화 |
| 목적 | 분석 최적화 | 원본 데이터 저장 |
| 기술 | Redshift, BigQuery, Snowflake, Presto 등 | AWS S3, Hadoop 기반 등 |
| 사용 목적 | BI 리포트, 대시보드 | 장기 보관, 머신러닝 학습 등 |

> **데이터 레이크 → (선별) → 데이터 웨어하우스 → 대시보드/분석**

---

## 👷‍♂️ 데이터 엔지니어의 역할

### 데이터 엔지니어란?
- 인프라 구축과 데이터를 전달하는 **플랫폼 설계자**
- 다양한 툴과 언어 사용:
  - Python, SQL, Java, Scala
  - Airflow, Spark, Kafka
  - Docker, Kubernetes (K8S)
  - AWS, GCP
  - MongoDB, Cassandra 등 NoSQL

### 주요 업무
- **ETL 파이프라인 구축**
- **데이터 웨어하우스 / 레이크 운영**
- **외부 데이터 수집 및 연결**
- **개인정보 분류 및 민감 데이터 관리**
- **분석가·과학자 지원을 위한 자동화된 파이프라인 구축**
- **ML 파이프라인(MLOps), LLMOps 도구 개발**

---

## 🔁 데이터 파이프라인 개요

### 데이터 흐름
> 데이터 소스 → 추출(Extract) → 정제(Transform) → 적재(Load) → 웨어하우스

### 파이프라인 종류

1. **ETL (Extract → Transform → Load)**  
   - 외부 데이터를 내부로 가져오기
   - 보통 데이터 엔지니어 담당
2. **ELT (Extract → Load → Transform)**  
   - 저장된 내부 데이터를 정제 및 요약 (SQL 활용)
   - 보통 데이터 분석가 or Analytics Engineer 담당
   - 도구: `DBT`
3. **Reverse ETL**
   - 내부 데이터를 외부 시스템(프로덕션)으로 전달
   - 예: 사용자 태그, 예측 모델 결과 등

---

## 🧾 ELT 요약 테이블

- 주요 요약 테이블 예시
  - `user_summary`, `client_summary`, `daily_activity` 등
- 주로 SQL의 `CTAS (Create Table As Select)` 사용
- **DBT**를 통한 관리 추세
- 이 테이블들은 분석과 대시보드의 기반

---

## 🔗 데이터 리니지 (Data Lineage)

> "이 데이터는 어디서 왔을까?"

- 데이터 흐름 추적이 가능한 구조 설계 필요
- 테이블 간의 **의존성 관리** 필수
- Core Table vs Temp Table 구분
- 문제 발생 시 추적이 쉬워야 함

---

## 🧠 참고 이미지 예시

> 데이터 아키텍처 및 역할 구분  
![DE vs DS](첨부이미지1.png)

> 데이터 파이프라인 구성 예시  
![Data Pipeline](첨부이미지2.png)

---

## 💡 마무리

데이터 인프라는 신뢰할 수 있는 데이터를 만들어내고,  
그 데이터를 통해 제품과 서비스를 개선하며,  
비즈니스 결정을 **데이터 중심**으로 변화시키는 핵심 기반입니다.

데이터 엔지니어는 이 모든 과정의 **중추적인 역할**을 맡습니다.
